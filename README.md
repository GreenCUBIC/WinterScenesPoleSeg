# Automatic Power Pole Segmentation in Adverse Weather Conditions from Vehicle-based RGB images using Deep Learning
Applying HRNet Semantic Segmentation Model to identify electric poles from Arctic Scenes and Adverse Weather Conditions

As an attempt to substantially automate the manual labour of critical electrical infrastructure maintenance, automatic segmentation of power poles is required. Various Deep Learning methods have shown learning capabilities for the same, for both UAV and ground-based imagery. This research study particularly focuses on the semantic segmentation of utility power poles from ground-based images taken under adverse weather conditions. The pre-trained High-Resolution Network (HRNet) architecture is used for dataset analysis and further finetuned using Google Street View (GSV) images with arctic weather scenery from the Iqaluit region in Nunavut, Canada, and the Canadian Adverse Driving Conditions (CADC) Dataset with ground-based imagery with adverse weather conditions from the Waterloo region in Ontario, Canada. Segmentation of poles in images with higher occlusion due to poor weather conditions proved to be the more difficult task. The HRNet model, which is trained for scene segmentation of ground-based imagery for multiple objects including poles, exhibits adaptability to learning semantic segmentation of poles in the GSV arctic urban images but significantly showcases a decrease in segmentation accuracy, even when examples of such images were included in the fine-tuning datasets.
